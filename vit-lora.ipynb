{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5808eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import timm\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchmetrics\n",
    "wandb.login(key=\"\") #your wandb key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e36ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters config\n",
    "config = {\n",
    "    \"root_dir\": '',\n",
    "    \"image_size\": 224,\n",
    "    \"num_workers\": 2,\n",
    "    \"batch_size\": 32, \n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"epochs\": 15,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    # Model & LoRA Config\n",
    "    \"vit_dropout\": 0.1,\n",
    "    \"lora_r\": 64,\n",
    "    \"lora_alpha\": 256,\n",
    "    \"lora_dropout\": 0.1,\n",
    "}\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data and adjust image df directory\n",
    "train_df = pd.read_csv('u1_train.csv', index_col=0) \n",
    "val_df = pd.read_csv('u1_val.csv', index_col=0) \n",
    "\n",
    "train_df.index = train_df.index.str.replace('CheXpert-v1.0-small', 'chexpert')\n",
    "val_df.index = val_df.index.str.replace('CheXpert-v1.0-small', 'chexpert')\n",
    "\n",
    "\n",
    "class_names = train_df.columns.tolist()\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Validation data shape: {val_df.shape}\")\n",
    "\n",
    "#Data augmentations\n",
    "def get_transforms(image_size):\n",
    "    \"\"\"Returns a dictionary of augmentation pipelines for each phase.\"\"\"\n",
    "    # Define normalization stats\n",
    "    normalize_transform = A.Normalize(\n",
    "        mean=[0.506, 0.506, 0.506],\n",
    "        std=[0.287, 0.287, 0.287]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'train': A.Compose([\n",
    "            A.Affine(scale=(0.95, 1.05), p=0.5),\n",
    "            A.OneOf([A.Affine(rotate=(-20, 20), p=0.5), A.Affine(shear=(-5, 5), p=0.5)], p=0.5),\n",
    "            A.Affine(translate_percent=(-0.05, 0.05), p=0.5),\n",
    "            A.Resize(image_size, image_size),\n",
    "            normalize_transform,\n",
    "            ToTensorV2()\n",
    "        ]),\n",
    "        'validation': A.Compose([\n",
    "            A.Resize(image_size, image_size),\n",
    "            normalize_transform,\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d926b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheXpertDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each call to __getitem__ returns an augmented image and its corresponding label.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_frame, root_dir, transform):\n",
    "        self.img_paths = [os.path.join(root_dir, path) for path in data_frame.index]\n",
    "        self.labels = torch.tensor(data_frame.values, dtype=torch.float32)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            image = np.array(Image.open(self.img_paths[idx]).convert(\"RGB\"))\n",
    "            image_tensor = self.transform(image=image)['image']\n",
    "            return image_tensor, self.labels[idx]\n",
    "        except (IOError, FileNotFoundError):\n",
    "            print(f\"Warning: Could not load image at {self.img_paths[idx]}. Returning zeros.\")\n",
    "            return torch.zeros((3, config[\"image_size\"], config[\"image_size\"])), torch.zeros(14)\n",
    "\n",
    "\n",
    "def get_weighted_sampler(data_frame):\n",
    "    \"\"\"\n",
    "    Creates a WeightedRandomSampler to handle class imbalance.\n",
    "    It gives more weight to samples from under-represented classes.\n",
    "    \"\"\"\n",
    "    class_weights = (1.0 / data_frame.sum(axis=0)).values\n",
    "    sample_weights = data_frame.dot(class_weights)\n",
    "    return WeightedRandomSampler(\n",
    "        weights=torch.tensor(sample_weights.values, dtype=torch.float),\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d8c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(cfg):\n",
    "    \"\"\"Main function to run the training and validation loop.\"\"\"\n",
    "    print(f\"Starting Supervised Training on {DEVICE}\")\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    transforms = get_transforms(cfg['image_size'])\n",
    "    train_dataset = CheXpertDataset(train_df, cfg[\"root_dir\"], transforms['train'])\n",
    "    val_dataset = CheXpertDataset(val_df, cfg[\"root_dir\"], transforms['validation'])\n",
    "    \n",
    "    sampler = get_weighted_sampler(train_df)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg[\"batch_size\"], sampler=sampler, num_workers=cfg[\"num_workers\"], pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=cfg[\"batch_size\"], shuffle=False, num_workers=cfg[\"num_workers\"], pin_memory=True)\n",
    "\n",
    "    # Initialize model\n",
    "    model = timm.create_model(\n",
    "        \"vit_base_patch16_224\", \n",
    "        pretrained=True, \n",
    "        num_classes=14,\n",
    "        drop_rate=cfg[\"vit_dropout\"]\n",
    "    )\n",
    "    \n",
    "    # Apply LoRA\n",
    "    lora_config = LoraConfig(\n",
    "        r=cfg[\"lora_r\"], \n",
    "        lora_alpha=cfg[\"lora_alpha\"], \n",
    "        target_modules=[\"qkv\", \"proj\"], \n",
    "        lora_dropout=cfg[\"lora_dropout\"], \n",
    "        bias=\"none\"\n",
    "    )\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.to(DEVICE)\n",
    "    model.print_trainable_parameters()\n",
    "    \n",
    "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=cfg[\"learning_rate\"], weight_decay=cfg[\"weight_decay\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg[\"epochs\"])\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    metric = torchmetrics.AUROC(task=\"multilabel\", num_labels=14, average=None).to(DEVICE)\n",
    "    scaler = torch.amp.GradScaler(enabled=(DEVICE.type == 'cuda'))\n",
    "\n",
    "    wandb.init(project=\"ViT-CheXpert-Supervised\", name=\"Standard-ViT-LoRA-Training\", config=cfg)\n",
    "    best_val_auc = 0\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(cfg[\"epochs\"]):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{cfg['epochs']}\", unit=\"batch\")\n",
    "        \n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.autocast(device_type=DEVICE.type, enabled=(DEVICE.type == 'cuda')):\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "                \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({\"Loss\": loss.item()})\n",
    "            \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        metric.reset()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                with torch.autocast(device_type=DEVICE.type, enabled=(DEVICE.type == 'cuda')):\n",
    "                    outputs = torch.sigmoid(model(images))\n",
    "                metric.update(outputs, labels.long())\n",
    "        \n",
    "        val_aucs = metric.compute()\n",
    "        mean_val_auc = torch.nanmean(val_aucs).item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val mAUROC: {mean_val_auc:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "        \n",
    "        log_dict = {\n",
    "            \"epoch\": epoch, \n",
    "            \"train_loss\": avg_train_loss, \n",
    "            \"val_mAUC\": mean_val_auc, \n",
    "            \"learning_rate\": scheduler.get_last_lr()[0]\n",
    "        }\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            log_dict[f\"val_auc_{class_name}\"] = val_aucs[i].item()\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "        if mean_val_auc > best_val_auc:\n",
    "            best_val_auc = mean_val_auc\n",
    "            epochs_no_improve = 0\n",
    "            \n",
    "            # Merge the adapters into the base model and save the full state dict\n",
    "            merged_model = model.merge_and_unload()\n",
    "            torch.save(merged_model.state_dict(), f\"./vit-lora-best-supervised-full.pth\")\n",
    "            \n",
    "            print(f\"New best model saved with mAUROC: {best_val_auc:.4f}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve >= cfg[\"early_stopping_patience\"]:\n",
    "            print(f\"Early stopping triggered after {epochs_no_improve} epochs with no improvement.\")\n",
    "            break\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "    wandb.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
